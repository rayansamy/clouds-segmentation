{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b98c09f623885d5b0bd80e3dec26763da8c2dc37efb14e056fac55c82470d720",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import hiddenlayer as hl\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "from gradcam import *\n",
    "from fnmatch import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "save_path = \"../../DATASETS/ISSI/ORGANIZED/\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "years = [\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\"]\n",
    "\n",
    "def look_for_file(rootdir, name):\n",
    "    regex = re.compile(name+\"*.jpeg\")\n",
    "\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            #print(\"file : \"+str(file))\n",
    "            if name in file:\n",
    "                #print(\"file : \"+str(file))\n",
    "                return file\n",
    "count = {\n",
    "            '0':0,\n",
    "            '1':0,\n",
    "            '2':0,\n",
    "            '3':0,\n",
    "            '4':0,\n",
    "            '5':0,\n",
    "        }\n",
    "for year in years:\n",
    "    df = pd.read_csv(\"../../DATASETS/ISSI/2007-2016 Organisation Summary/\"+year+\"-Summary-\"+year+\"-Summary.csv\")\n",
    "    print(\" File : \"+str(\"../../DATASETS/ISSI/2007-2016 Organisation Summary/\"+year+\"-Summary-\"+year+\"-Summary.csv\"))\n",
    "    #print(df)\n",
    "    for index, row in df.iterrows():\n",
    "        cols = list(df.columns)\n",
    "        classes = {\n",
    "            '0':0,\n",
    "            '1':0,\n",
    "            '2':0,\n",
    "            '3':0,\n",
    "            '4':0,\n",
    "            '5':0,\n",
    "        }\n",
    "        try:\n",
    "            classes[ str(  row[cols[2]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "        try:\n",
    "            classes[ str(  row[cols[3]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "        try:\n",
    "            classes[ str(  row[cols[4]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "        try:\n",
    "            classes[ str(  row[cols[5]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "            \n",
    "        try:\n",
    "            classes[ str(  row[cols[6]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "            \n",
    "        try:\n",
    "            classes[ str(  row[cols[7]]  )  ] += 1\n",
    "        except:\n",
    "            classes['0'] += 1\n",
    "        \n",
    "        #print(\"row : \"+str(row))\n",
    "        datetime_object = datetime.datetime.strptime(row['Day'].split()[0], \"%b\")\n",
    "        month_number = datetime_object.month\n",
    "        day = row['Day'].split()[1]\n",
    "        path = \"../../DATASETS/ISSI/images/\"\n",
    "        name_file = \"Aqua_CorrectedReflectance{year:04d}{month:02d}{day:02d}\" #\".png\"\n",
    "        ex_path = name_file.format(year=int(year), month=int(month_number), day=int(day))\n",
    "        best = max(classes, key=classes.get)\n",
    "        filename = look_for_file(path,ex_path)\n",
    "        file_img = path+filename\n",
    "        img = Image.open(file_img)\n",
    "        imges = cv2.imread(file_img,1)\n",
    "        \"\"\"\n",
    "        if [0, 0, 0] in imges:\n",
    "            continue\n",
    "        \"\"\"\n",
    "        if best in ['1','2','3','4','5']:\n",
    "            sav_path = save_path+str(best)+\"/\"+str(count[best])+\".jpeg\"\n",
    "            #print(\"save path : \"+str(sav_path))\n",
    "            count[best] += 1\n",
    "            img.save(sav_path)\n",
    "        #print(\"Best : \"+str(best))\n",
    "        #print(\"Classes : \"+str(classes))\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PERCENTAGE_TEST = 0.4\n",
    "BATCH_SIZE = 32\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize([768, 512]),\n",
    "    # you can add other transformations in this list\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root=\"../../DATASETS/ISSI/ORGANIZED/\", transform=transformer)\n",
    "\n",
    "dataloader  = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = 'cpu' \n",
    "\"\"\"\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(100, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(20, 4),\n",
    "    nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "model.load_state_dict(torch.load(\"../zooniverse-resized-image_state_dict\", map_location=device))\n",
    "\n",
    "\"\"\"\n",
    "model = torch.load(\"../zooniverse-resized-image_net_model\", map_location=device)\n",
    "\"\"\"\n",
    "transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "\n",
    "graph = hl.build_graph(model, torch.zeros([1, 3, 224, 224]))\n",
    "graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "graph.save('model_hiddenlayer', format='png')\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nb_classes = 4\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "cfs_mat = confusion_matrix\n",
    "associations = ['Fish', 'Flower', 'Gravel', 'Sugar']\n",
    "associations_model = ['Flower', 'Fish', 'Gravel', 'Sugar']\n",
    "print(confusion_matrix[0])\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "plt.title(\"Confusion Matrix for ISSI Images\")\n",
    "sns.set(font_scale=1.8)\n",
    "sns.heatmap(cfs_mat, annot=True, fmt='', ax=ax, linewidths=.9, yticklabels=associations, xticklabels=associations_model)\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "print(cfs_mat[:4,:].shape)\n",
    "print(   np.sum(  cfs_mat[:4,:], axis=1  ).shape  )\n",
    "print(   (  cfs_mat[:4,:].T/np.sum(cfs_mat[:4,:], axis=1)    ).shape  )\n",
    "plt.title(\"Confusion Matrix Clusters MODIS model %\")\n",
    "sns.heatmap( (cfs_mat[:4,:].T/np.sum(cfs_mat[:4,:], axis=1)).T, annot=True, \n",
    "            fmt='.2%', cmap='Blues' , yticklabels=associations)\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(dataset.classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\r\n",
    "import datetime\r\n",
    "import re\r\n",
    "\r\n",
    "import torchvision.models as models\r\n",
    "from torchvision.datasets import ImageFolder\r\n",
    "import torch\r\n",
    "from torchvision import transforms\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from torch.autograd import Variable\r\n",
    "from collections import OrderedDict\r\n",
    "import pandas as pd\r\n",
    "import hiddenlayer as hl\r\n",
    "import glob\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "from gradcam import *\r\n",
    "from fnmatch import fnmatch\r\n",
    "save_path = \"../../DATASETS/ISSI/ORGANIZED/\"\r\n",
    "\r\n",
    "device = 'cpu' \r\n",
    "\r\n",
    "model = models.resnet18(pretrained=True)\r\n",
    "\r\n",
    "\r\n",
    "model.fc = nn.Sequential(\r\n",
    "    nn.Linear(512, 100),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(100, 20),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(20, 4),\r\n",
    "    nn.LogSoftmax(dim=1)\r\n",
    "    )\r\n",
    "model.load_state_dict(torch.load(\"../zooniverse-resized-image_state_dict\", map_location=device))\r\n",
    "\r\n",
    "\r\n",
    "root = save_path\r\n",
    "pattern = \"*.jpeg\"\r\n",
    "pathes = []\r\n",
    "for path, subdirs, files in os.walk(root):\r\n",
    "    for name in files:\r\n",
    "        if fnmatch(name, pattern):\r\n",
    "            pathes.append(os.path.join(path, name))\r\n",
    "#pathes =  [\"../data/3.jpg\"]\r\n",
    "#pathes = pathes.reverse()\r\n",
    "associations = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "done = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "count = 0\r\n",
    "while len(done)!=0:\r\n",
    "    #print(\"Image \"+str(count))\r\n",
    "    \"\"\"\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    classes = classes.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    print(\"SHAPE : \"+str(inputs.shape))\r\n",
    "    \"\"\"\r\n",
    "    path = random.choice(pathes)\r\n",
    "    pil_img = Image.open(path)\r\n",
    "    inputs = transformer(pil_img).unsqueeze_(0)\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    \r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    \"\"\"\r\n",
    "    print(\"path : \"+str(path))\r\n",
    "    print(\"outputs : \"+str(outputs))\r\n",
    "    print(\"ASSO : \"+str(associations[int(preds[0])]))\r\n",
    "    print(\"preds : \"+str(int(preds[0])))\r\n",
    "    \"\"\"\r\n",
    "    if len(done) == 0:\r\n",
    "        break\r\n",
    "    if associations[preds[0]] not in done:\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        done.remove(associations[int(preds[0])])\r\n",
    "        predict_image(model, path, str(associations[preds[0]]))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\r\n",
    "import datetime\r\n",
    "import re\r\n",
    "\r\n",
    "import torchvision.models as models\r\n",
    "from torchvision.datasets import ImageFolder\r\n",
    "import torch\r\n",
    "from torchvision import transforms\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from torch.autograd import Variable\r\n",
    "from collections import OrderedDict\r\n",
    "import pandas as pd\r\n",
    "import hiddenlayer as hl\r\n",
    "import glob\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "from gradcam import *\r\n",
    "from fnmatch import fnmatch\r\n",
    "save_path = \"../../DATASETS/CLASSIF_RESIZED/\"\r\n",
    "\r\n",
    "device = 'cpu' \r\n",
    "\r\n",
    "model = models.resnet18(pretrained=True)\r\n",
    "\r\n",
    "\r\n",
    "model.fc = nn.Sequential(\r\n",
    "    nn.Linear(512, 100),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(100, 20),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(20, 4),\r\n",
    "    nn.LogSoftmax(dim=1)\r\n",
    "    )\r\n",
    "model.load_state_dict(torch.load(\"../zooniverse-resized-image_state_dict\", map_location=device))\r\n",
    "\r\n",
    "\r\n",
    "root = save_path\r\n",
    "pattern = \"*.jpeg\"\r\n",
    "pathes = []\r\n",
    "for path, subdirs, files in os.walk(root):\r\n",
    "    for name in files:\r\n",
    "        if fnmatch(name, pattern):\r\n",
    "            pathes.append(os.path.join(path, name))\r\n",
    "#pathes =  [\"../data/3.jpg\"]\r\n",
    "#pathes = pathes.reverse()\r\n",
    "associations = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "done = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "count = 0\r\n",
    "while len(done)!=0:\r\n",
    "    #print(\"Image \"+str(count))\r\n",
    "    \"\"\"\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    classes = classes.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    print(\"SHAPE : \"+str(inputs.shape))\r\n",
    "    \"\"\"\r\n",
    "    path = random.choice(pathes)\r\n",
    "    pil_img = Image.open(path)\r\n",
    "    inputs = transformer(pil_img).unsqueeze_(0)\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    \r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    \"\"\"\r\n",
    "    print(\"path : \"+str(path))\r\n",
    "    print(\"outputs : \"+str(outputs))\r\n",
    "    print(\"ASSO : \"+str(associations[int(preds[0])]))\r\n",
    "    print(\"preds : \"+str(int(preds[0])))\r\n",
    "    \"\"\"\r\n",
    "    if len(done) == 0:\r\n",
    "        break\r\n",
    "    if associations[preds[0]] not in done:\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        done.remove(associations[int(preds[0])])\r\n",
    "        predict_image(model, path, str(associations[preds[0]]))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\r\n",
    "import datetime\r\n",
    "import re\r\n",
    "\r\n",
    "import torchvision.models as models\r\n",
    "from torchvision.datasets import ImageFolder\r\n",
    "import torch\r\n",
    "from torchvision import transforms\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from torch.autograd import Variable\r\n",
    "from collections import OrderedDict\r\n",
    "import pandas as pd\r\n",
    "import hiddenlayer as hl\r\n",
    "import glob\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "from gradcam import *\r\n",
    "from fnmatch import fnmatch\r\n",
    "save_path = \"../../DATASETS/EURE4CA/tmp/train/\"\r\n",
    "\r\n",
    "device = 'cpu' \r\n",
    "\r\n",
    "model = models.resnet18(pretrained=True)\r\n",
    "\r\n",
    "\r\n",
    "model.fc = nn.Sequential(\r\n",
    "    nn.Linear(512, 100),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(100, 20),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Dropout(0.5),\r\n",
    "\r\n",
    "    nn.Linear(20, 4),\r\n",
    "    nn.LogSoftmax(dim=1)\r\n",
    "    )\r\n",
    "model.load_state_dict(torch.load(\"../zooniverse-resized-image_state_dict\", map_location=device))\r\n",
    "\r\n",
    "\r\n",
    "root = save_path\r\n",
    "pattern = \"*.png\"\r\n",
    "pathes = []\r\n",
    "for path, subdirs, files in os.walk(root):\r\n",
    "    for name in files:\r\n",
    "        if fnmatch(name, pattern):\r\n",
    "            pathes.append(os.path.join(path, name))\r\n",
    "#pathes =  [\"../data/3.jpg\"]\r\n",
    "#pathes = pathes.reverse()\r\n",
    "associations = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "done = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]\r\n",
    "count = 0\r\n",
    "while len(done)!=0:\r\n",
    "    #print(\"Image \"+str(count))\r\n",
    "    \"\"\"\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    classes = classes.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    print(\"SHAPE : \"+str(inputs.shape))\r\n",
    "    \"\"\"\r\n",
    "    path = random.choice(pathes)\r\n",
    "    pil_img = Image.open(path)\r\n",
    "    inputs = transformer(pil_img).unsqueeze_(0)\r\n",
    "    inputs = inputs.to(device)\r\n",
    "    outputs = model(inputs)\r\n",
    "    \r\n",
    "    _, preds = torch.max(outputs, 1)\r\n",
    "    \"\"\"\r\n",
    "    print(\"path : \"+str(path))\r\n",
    "    print(\"outputs : \"+str(outputs))\r\n",
    "    print(\"ASSO : \"+str(associations[int(preds[0])]))\r\n",
    "    print(\"preds : \"+str(int(preds[0])))\r\n",
    "    \"\"\"\r\n",
    "    if len(done) == 0:\r\n",
    "        break\r\n",
    "    if associations[preds[0]] not in done:\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        done.remove(associations[int(preds[0])])\r\n",
    "        predict_image(model, path, str(associations[preds[0]]))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import hiddenlayer as hl\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "from gradcam import *\n",
    "from fnmatch import fnmatch\n",
    "IMAGE_FOLDER = \"../../DATASETS/CLASSIF_RESIZED/\"\n",
    "BATCH_SIZE = 16\n",
    "device = 'cpu' \n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(100, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(20, 4),\n",
    "    nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "model.load_state_dict(torch.load(\"../zooniverse-resized-image_state_dict\", map_location=device))\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize([768, 512]),\n",
    "    # you can add other transformations in this list\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "dataset = ImageFolder(root=IMAGE_FOLDER, transform=transformer)\n",
    "print(len(dataset))\n",
    "n = len(dataset)\n",
    "n_test = int(0.1 * n)  # take ~10% for test\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-n_test, n_test], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "train_dataloader  = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=1) \n",
    "test_dataloader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "nb_classes = 4\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "cfs_mat = confusion_matrix.numpy()\n",
    "associations = ['Fish', 'Flower', 'Gravel', 'Sugar']\n",
    "print(confusion_matrix[0])\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "plt.title(\"Confusion Matrix on test Zooniverse resized Images\")\n",
    "sns.set(font_scale=1.8)\n",
    "sns.heatmap(cfs_mat, annot=True, fmt='', ax=ax, linewidths=.9, yticklabels=associations, xticklabels=associations)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.title(\"Confusion Matrix on test Zooniverse resized Images %\")\n",
    "a = cfs_mat.T\n",
    "b = np.sum(cfs_mat, axis=1)\n",
    "sns.heatmap( (cfs_mat.T/np.sum(cfs_mat, axis=1)).T, annot=True, \n",
    "            fmt='.2%', cmap='Blues' , yticklabels=associations, xticklabels=associations)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"N = \"+str(n))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}