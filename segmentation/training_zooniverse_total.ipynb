{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b98c09f623885d5b0bd80e3dec26763da8c2dc37efb14e056fac55c82470d720",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: raysamram (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.30<br/>\n                Syncing run <strong style=\"color:#cdcd00\">dandy-darkness-31</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/raysamram/clouds-segmentation\" target=\"_blank\">https://wandb.ai/raysamram/clouds-segmentation</a><br/>\n                Run page: <a href=\"https://wandb.ai/raysamram/clouds-segmentation/runs/34h957pu\" target=\"_blank\">https://wandb.ai/raysamram/clouds-segmentation/runs/34h957pu</a><br/>\n                Run data is saved locally in <code>c:\\Users\\Ray\\Documents\\Stage\\clouds-segmentation\\segmentation\\wandb\\run-20210521_115806-34h957pu</code><br/><br/>\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='clouds-segmentation', entity='raysamram')\n",
    "config = wandb.config\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from architecture import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "PERCENTAGE_TEST = 0.2\n",
    "\n",
    "config.learning_rate = LEARNING_RATE\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.dataset = \"ZOONIVERSE ALL-IMAGE\"\n",
    "config.epochs = EPOCHS\n",
    "config.percentage_test = PERCENTAGE_TEST\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "transformer = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Resize([768, 512]),\n",
    "    # you can add other transformations in this list\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "dataset = ImageFolder(root=\"../../DATASETS/ISSI/ORGANIZED/\", transform=transformer)\n",
    "n = len(dataset)\n",
    "n_test = int(0.1 * n)  # take ~10% for test\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-n_test, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.number_train_images = len(train_set)\n",
    "config.number_test_images = len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader  = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=1) \n",
    "test_dataloader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(100, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(20, 5),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "pretrained_model.to(device)\n",
    "net = pretrained_model\n",
    "\n",
    "#net = CNet()\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NET : ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=512, out_features=100, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=100, out_features=20, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=20, out_features=5, bias=True)\n    (7): LogSoftmax(dim=1)\n  )\n)\nLogSoftMax shape : torch.Size([3, 5])\nTarget shape : torch.Size([3])\ninput:  tensor([[ 1.6176, -0.2095,  1.3491, -0.2777,  1.3247],\n        [ 0.5561,  1.1416, -0.5937, -0.5375,  0.0676],\n        [ 0.4659,  0.3454,  0.8371, -0.1210,  0.2429]], requires_grad=True)\ntarget:  tensor([1, 0, 4])\noutput:  tensor(2.0116, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "print(\"NET : \"+str(net))\r\n",
    "input = torch.randn(3, 5, requires_grad=True)\r\n",
    "# every element in target should have 0 <= value < C\r\n",
    "target = torch.tensor([1, 0, 4])\r\n",
    "\r\n",
    "m = nn.LogSoftmax(dim=1)\r\n",
    "nll_loss = nn.NLLLoss()\r\n",
    "output = nll_loss(m(input), target)\r\n",
    "output.backward()\r\n",
    "\r\n",
    "print(\"LogSoftMax shape : \"+str(m(input).shape))\r\n",
    "print(\"Target shape : \"+str(target.shape))\r\n",
    "\r\n",
    "print('input: ', input)\r\n",
    "print('target: ', target)\r\n",
    "print('output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch : 0\n",
      "Epoch 0.. Step 0.. Train loss: 0.335.. Test loss: 1.657.. Test accuracy: 0.156\n",
      "Epoch 0.. Step 10.. Train loss: 3.184.. Test loss: 1.552.. Test accuracy: 0.406\n",
      "Epoch 0.. Step 20.. Train loss: 3.108.. Test loss: 1.540.. Test accuracy: 0.406\n",
      "Epoch : 1\n",
      "Epoch 1.. Step 0.. Train loss: 2.739.. Test loss: 1.595.. Test accuracy: 0.406\n",
      "Epoch 1.. Step 10.. Train loss: 2.936.. Test loss: 1.377.. Test accuracy: 0.641\n",
      "Epoch 1.. Step 20.. Train loss: 2.790.. Test loss: 1.302.. Test accuracy: 0.641\n",
      "Epoch : 2\n",
      "Epoch 2.. Step 0.. Train loss: 2.698.. Test loss: 1.279.. Test accuracy: 0.641\n",
      "Epoch 2.. Step 10.. Train loss: 2.885.. Test loss: 1.616.. Test accuracy: 0.406\n",
      "Epoch 2.. Step 20.. Train loss: 2.933.. Test loss: 1.269.. Test accuracy: 0.641\n",
      "Epoch : 3\n",
      "Epoch 3.. Step 0.. Train loss: 2.764.. Test loss: 1.579.. Test accuracy: 0.406\n",
      "Epoch 3.. Step 10.. Train loss: 2.850.. Test loss: 1.481.. Test accuracy: 0.406\n",
      "Epoch 3.. Step 20.. Train loss: 2.865.. Test loss: 1.399.. Test accuracy: 0.406\n",
      "Epoch : 4\n",
      "Epoch 4.. Step 0.. Train loss: 2.481.. Test loss: 1.252.. Test accuracy: 0.641\n",
      "Epoch 4.. Step 10.. Train loss: 2.810.. Test loss: 1.444.. Test accuracy: 0.406\n",
      "Epoch 4.. Step 20.. Train loss: 2.757.. Test loss: 1.573.. Test accuracy: 0.406\n",
      "Epoch : 5\n",
      "Epoch 5.. Step 0.. Train loss: 2.537.. Test loss: 1.237.. Test accuracy: 0.641\n",
      "Epoch 5.. Step 10.. Train loss: 2.806.. Test loss: 1.215.. Test accuracy: 0.641\n",
      "Epoch 5.. Step 20.. Train loss: 2.808.. Test loss: 1.168.. Test accuracy: 0.641\n",
      "Epoch : 6\n",
      "Epoch 6.. Step 0.. Train loss: 2.839.. Test loss: 1.407.. Test accuracy: 0.406\n",
      "Epoch 6.. Step 10.. Train loss: 2.798.. Test loss: 1.193.. Test accuracy: 0.641\n",
      "Epoch 6.. Step 20.. Train loss: 2.776.. Test loss: 1.248.. Test accuracy: 0.641\n",
      "Epoch : 7\n",
      "Epoch 7.. Step 0.. Train loss: 2.637.. Test loss: 1.222.. Test accuracy: 0.641\n",
      "Epoch 7.. Step 10.. Train loss: 2.946.. Test loss: 1.210.. Test accuracy: 0.641\n",
      "Epoch 7.. Step 20.. Train loss: 2.731.. Test loss: 1.226.. Test accuracy: 0.641\n",
      "Epoch : 8\n",
      "Epoch 8.. Step 0.. Train loss: 2.533.. Test loss: 1.452.. Test accuracy: 0.406\n",
      "Epoch 8.. Step 10.. Train loss: 2.931.. Test loss: 1.211.. Test accuracy: 0.641\n",
      "Epoch 8.. Step 20.. Train loss: 2.632.. Test loss: 1.204.. Test accuracy: 0.641\n",
      "Epoch : 9\n",
      "Epoch 9.. Step 0.. Train loss: 2.310.. Test loss: 1.507.. Test accuracy: 0.406\n",
      "Epoch 9.. Step 10.. Train loss: 2.648.. Test loss: 1.404.. Test accuracy: 0.406\n",
      "Epoch 9.. Step 20.. Train loss: 2.807.. Test loss: 1.172.. Test accuracy: 0.641\n",
      "Epoch : 10\n",
      "Epoch 10.. Step 0.. Train loss: 2.411.. Test loss: 1.399.. Test accuracy: 0.406\n",
      "Epoch 10.. Step 10.. Train loss: 2.810.. Test loss: 1.172.. Test accuracy: 0.641\n",
      "Epoch 10.. Step 20.. Train loss: 2.644.. Test loss: 1.400.. Test accuracy: 0.406\n",
      "Epoch : 11\n",
      "Epoch 11.. Step 0.. Train loss: 2.436.. Test loss: 1.403.. Test accuracy: 0.406\n",
      "Epoch 11.. Step 10.. Train loss: 2.813.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch 11.. Step 20.. Train loss: 2.628.. Test loss: 1.385.. Test accuracy: 0.406\n",
      "Epoch : 12\n",
      "Epoch 12.. Step 0.. Train loss: 2.661.. Test loss: 1.485.. Test accuracy: 0.406\n",
      "Epoch 12.. Step 10.. Train loss: 2.734.. Test loss: 1.232.. Test accuracy: 0.641\n",
      "Epoch 12.. Step 20.. Train loss: 2.750.. Test loss: 1.214.. Test accuracy: 0.641\n",
      "Epoch : 13\n",
      "Epoch 13.. Step 0.. Train loss: 2.725.. Test loss: 1.219.. Test accuracy: 0.641\n",
      "Epoch 13.. Step 10.. Train loss: 2.819.. Test loss: 1.247.. Test accuracy: 0.641\n",
      "Epoch 13.. Step 20.. Train loss: 2.687.. Test loss: 1.176.. Test accuracy: 0.641\n",
      "Epoch : 14\n",
      "Epoch 14.. Step 0.. Train loss: 2.576.. Test loss: 1.407.. Test accuracy: 0.406\n",
      "Epoch 14.. Step 10.. Train loss: 2.739.. Test loss: 1.199.. Test accuracy: 0.641\n",
      "Epoch 14.. Step 20.. Train loss: 2.587.. Test loss: 1.199.. Test accuracy: 0.641\n",
      "Epoch : 15\n",
      "Epoch 15.. Step 0.. Train loss: 2.522.. Test loss: 1.192.. Test accuracy: 0.641\n",
      "Epoch 15.. Step 10.. Train loss: 2.760.. Test loss: 1.494.. Test accuracy: 0.406\n",
      "Epoch 15.. Step 20.. Train loss: 2.716.. Test loss: 1.195.. Test accuracy: 0.641\n",
      "Epoch : 16\n",
      "Epoch 16.. Step 0.. Train loss: 2.342.. Test loss: 1.192.. Test accuracy: 0.641\n",
      "Epoch 16.. Step 10.. Train loss: 2.814.. Test loss: 1.382.. Test accuracy: 0.406\n",
      "Epoch 16.. Step 20.. Train loss: 2.714.. Test loss: 1.179.. Test accuracy: 0.641\n",
      "Epoch : 17\n",
      "Epoch 17.. Step 0.. Train loss: 2.229.. Test loss: 1.403.. Test accuracy: 0.406\n",
      "Epoch 17.. Step 10.. Train loss: 2.711.. Test loss: 1.414.. Test accuracy: 0.406\n",
      "Epoch 17.. Step 20.. Train loss: 2.679.. Test loss: 1.415.. Test accuracy: 0.406\n",
      "Epoch : 18\n",
      "Epoch 18.. Step 0.. Train loss: 2.632.. Test loss: 1.144.. Test accuracy: 0.641\n",
      "Epoch 18.. Step 10.. Train loss: 2.778.. Test loss: 1.182.. Test accuracy: 0.641\n",
      "Epoch 18.. Step 20.. Train loss: 2.721.. Test loss: 1.177.. Test accuracy: 0.641\n",
      "Epoch : 19\n",
      "Epoch 19.. Step 0.. Train loss: 2.544.. Test loss: 1.198.. Test accuracy: 0.641\n",
      "Epoch 19.. Step 10.. Train loss: 2.760.. Test loss: 1.195.. Test accuracy: 0.641\n",
      "Epoch 19.. Step 20.. Train loss: 2.705.. Test loss: 1.201.. Test accuracy: 0.641\n",
      "Epoch : 20\n",
      "Epoch 20.. Step 0.. Train loss: 2.379.. Test loss: 1.425.. Test accuracy: 0.406\n",
      "Epoch 20.. Step 10.. Train loss: 2.707.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch 20.. Step 20.. Train loss: 2.765.. Test loss: 1.443.. Test accuracy: 0.406\n",
      "Epoch : 21\n",
      "Epoch 21.. Step 0.. Train loss: 2.325.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch 21.. Step 10.. Train loss: 2.614.. Test loss: 1.462.. Test accuracy: 0.406\n",
      "Epoch 21.. Step 20.. Train loss: 2.615.. Test loss: 1.373.. Test accuracy: 0.406\n",
      "Epoch : 22\n",
      "Epoch 22.. Step 0.. Train loss: 2.340.. Test loss: 1.383.. Test accuracy: 0.406\n",
      "Epoch 22.. Step 10.. Train loss: 2.801.. Test loss: 1.161.. Test accuracy: 0.641\n",
      "Epoch 22.. Step 20.. Train loss: 2.675.. Test loss: 1.164.. Test accuracy: 0.641\n",
      "Epoch : 23\n",
      "Epoch 23.. Step 0.. Train loss: 2.404.. Test loss: 1.417.. Test accuracy: 0.406\n",
      "Epoch 23.. Step 10.. Train loss: 2.775.. Test loss: 1.379.. Test accuracy: 0.406\n",
      "Epoch 23.. Step 20.. Train loss: 2.612.. Test loss: 1.184.. Test accuracy: 0.641\n",
      "Epoch : 24\n",
      "Epoch 24.. Step 0.. Train loss: 2.520.. Test loss: 1.370.. Test accuracy: 0.406\n",
      "Epoch 24.. Step 10.. Train loss: 2.773.. Test loss: 1.407.. Test accuracy: 0.406\n",
      "Epoch 24.. Step 20.. Train loss: 2.676.. Test loss: 1.375.. Test accuracy: 0.406\n",
      "Epoch : 25\n",
      "Epoch 25.. Step 0.. Train loss: 2.327.. Test loss: 1.139.. Test accuracy: 0.641\n",
      "Epoch 25.. Step 10.. Train loss: 2.888.. Test loss: 1.676.. Test accuracy: 0.406\n",
      "Epoch 25.. Step 20.. Train loss: 2.686.. Test loss: 1.175.. Test accuracy: 0.641\n",
      "Epoch : 26\n",
      "Epoch 26.. Step 0.. Train loss: 2.221.. Test loss: 1.444.. Test accuracy: 0.406\n",
      "Epoch 26.. Step 10.. Train loss: 2.739.. Test loss: 1.171.. Test accuracy: 0.641\n",
      "Epoch 26.. Step 20.. Train loss: 2.682.. Test loss: 1.385.. Test accuracy: 0.406\n",
      "Epoch : 27\n",
      "Epoch 27.. Step 0.. Train loss: 2.154.. Test loss: 1.358.. Test accuracy: 0.406\n",
      "Epoch 27.. Step 10.. Train loss: 2.568.. Test loss: 1.150.. Test accuracy: 0.641\n",
      "Epoch 27.. Step 20.. Train loss: 2.932.. Test loss: 1.130.. Test accuracy: 0.641\n",
      "Epoch : 28\n",
      "Epoch 28.. Step 0.. Train loss: 2.492.. Test loss: 1.445.. Test accuracy: 0.406\n",
      "Epoch 28.. Step 10.. Train loss: 2.673.. Test loss: 1.390.. Test accuracy: 0.406\n",
      "Epoch 28.. Step 20.. Train loss: 2.726.. Test loss: 1.211.. Test accuracy: 0.641\n",
      "Epoch : 29\n",
      "Epoch 29.. Step 0.. Train loss: 2.413.. Test loss: 1.396.. Test accuracy: 0.406\n",
      "Epoch 29.. Step 10.. Train loss: 2.737.. Test loss: 1.164.. Test accuracy: 0.641\n",
      "Epoch 29.. Step 20.. Train loss: 2.641.. Test loss: 1.180.. Test accuracy: 0.641\n",
      "Epoch : 30\n",
      "Epoch 30.. Step 0.. Train loss: 2.551.. Test loss: 1.440.. Test accuracy: 0.406\n",
      "Epoch 30.. Step 10.. Train loss: 2.756.. Test loss: 1.180.. Test accuracy: 0.641\n",
      "Epoch 30.. Step 20.. Train loss: 2.628.. Test loss: 1.191.. Test accuracy: 0.641\n",
      "Epoch : 31\n",
      "Epoch 31.. Step 0.. Train loss: 2.265.. Test loss: 1.448.. Test accuracy: 0.406\n",
      "Epoch 31.. Step 10.. Train loss: 2.685.. Test loss: 1.165.. Test accuracy: 0.641\n",
      "Epoch 31.. Step 20.. Train loss: 2.652.. Test loss: 1.385.. Test accuracy: 0.406\n",
      "Epoch : 32\n",
      "Epoch 32.. Step 0.. Train loss: 2.790.. Test loss: 1.168.. Test accuracy: 0.641\n",
      "Epoch 32.. Step 10.. Train loss: 2.714.. Test loss: 1.406.. Test accuracy: 0.406\n",
      "Epoch 32.. Step 20.. Train loss: 2.684.. Test loss: 1.346.. Test accuracy: 0.406\n",
      "Epoch : 33\n",
      "Epoch 33.. Step 0.. Train loss: 2.401.. Test loss: 1.428.. Test accuracy: 0.406\n",
      "Epoch 33.. Step 10.. Train loss: 2.799.. Test loss: 1.191.. Test accuracy: 0.641\n",
      "Epoch 33.. Step 20.. Train loss: 2.671.. Test loss: 1.206.. Test accuracy: 0.641\n",
      "Epoch : 34\n",
      "Epoch 34.. Step 0.. Train loss: 2.378.. Test loss: 1.401.. Test accuracy: 0.406\n",
      "Epoch 34.. Step 10.. Train loss: 2.597.. Test loss: 1.405.. Test accuracy: 0.406\n",
      "Epoch 34.. Step 20.. Train loss: 2.748.. Test loss: 1.150.. Test accuracy: 0.641\n",
      "Epoch : 35\n",
      "Epoch 35.. Step 0.. Train loss: 2.340.. Test loss: 1.361.. Test accuracy: 0.406\n",
      "Epoch 35.. Step 10.. Train loss: 2.821.. Test loss: 1.178.. Test accuracy: 0.641\n",
      "Epoch 35.. Step 20.. Train loss: 2.703.. Test loss: 1.418.. Test accuracy: 0.406\n",
      "Epoch : 36\n",
      "Epoch 36.. Step 0.. Train loss: 2.238.. Test loss: 1.183.. Test accuracy: 0.641\n",
      "Epoch 36.. Step 10.. Train loss: 2.614.. Test loss: 1.360.. Test accuracy: 0.406\n",
      "Epoch 36.. Step 20.. Train loss: 2.836.. Test loss: 1.166.. Test accuracy: 0.641\n",
      "Epoch : 37\n",
      "Epoch 37.. Step 0.. Train loss: 2.431.. Test loss: 1.176.. Test accuracy: 0.641\n",
      "Epoch 37.. Step 10.. Train loss: 2.641.. Test loss: 1.343.. Test accuracy: 0.406\n",
      "Epoch 37.. Step 20.. Train loss: 2.793.. Test loss: 1.427.. Test accuracy: 0.406\n",
      "Epoch : 38\n",
      "Epoch 38.. Step 0.. Train loss: 2.171.. Test loss: 1.162.. Test accuracy: 0.641\n",
      "Epoch 38.. Step 10.. Train loss: 2.723.. Test loss: 1.405.. Test accuracy: 0.406\n",
      "Epoch 38.. Step 20.. Train loss: 2.723.. Test loss: 1.446.. Test accuracy: 0.406\n",
      "Epoch : 39\n",
      "Epoch 39.. Step 0.. Train loss: 2.525.. Test loss: 1.143.. Test accuracy: 0.641\n",
      "Epoch 39.. Step 10.. Train loss: 2.538.. Test loss: 1.160.. Test accuracy: 0.641\n",
      "Epoch 39.. Step 20.. Train loss: 2.731.. Test loss: 1.439.. Test accuracy: 0.406\n",
      "Epoch : 40\n",
      "Epoch 40.. Step 0.. Train loss: 2.457.. Test loss: 1.431.. Test accuracy: 0.406\n",
      "Epoch 40.. Step 10.. Train loss: 2.896.. Test loss: 1.361.. Test accuracy: 0.406\n",
      "Epoch 40.. Step 20.. Train loss: 2.638.. Test loss: 1.176.. Test accuracy: 0.641\n",
      "Epoch : 41\n",
      "Epoch 41.. Step 0.. Train loss: 2.223.. Test loss: 1.161.. Test accuracy: 0.641\n",
      "Epoch 41.. Step 10.. Train loss: 2.535.. Test loss: 1.133.. Test accuracy: 0.641\n",
      "Epoch 41.. Step 20.. Train loss: 2.735.. Test loss: 1.158.. Test accuracy: 0.641\n",
      "Epoch : 42\n",
      "Epoch 42.. Step 0.. Train loss: 2.417.. Test loss: 1.140.. Test accuracy: 0.641\n",
      "Epoch 42.. Step 10.. Train loss: 2.671.. Test loss: 1.377.. Test accuracy: 0.406\n",
      "Epoch 42.. Step 20.. Train loss: 2.652.. Test loss: 1.537.. Test accuracy: 0.406\n",
      "Epoch : 43\n",
      "Epoch 43.. Step 0.. Train loss: 2.277.. Test loss: 1.153.. Test accuracy: 0.641\n",
      "Epoch 43.. Step 10.. Train loss: 2.659.. Test loss: 1.139.. Test accuracy: 0.641\n",
      "Epoch 43.. Step 20.. Train loss: 2.707.. Test loss: 1.149.. Test accuracy: 0.641\n",
      "Epoch : 44\n",
      "Epoch 44.. Step 0.. Train loss: 2.191.. Test loss: 1.149.. Test accuracy: 0.641\n",
      "Epoch 44.. Step 10.. Train loss: 2.753.. Test loss: 1.479.. Test accuracy: 0.406\n",
      "Epoch 44.. Step 20.. Train loss: 2.481.. Test loss: 1.155.. Test accuracy: 0.641\n",
      "Epoch : 45\n",
      "Epoch 45.. Step 0.. Train loss: 2.245.. Test loss: 1.525.. Test accuracy: 0.406\n",
      "Epoch 45.. Step 10.. Train loss: 2.643.. Test loss: 1.411.. Test accuracy: 0.406\n",
      "Epoch 45.. Step 20.. Train loss: 2.602.. Test loss: 1.375.. Test accuracy: 0.406\n",
      "Epoch : 46\n",
      "Epoch 46.. Step 0.. Train loss: 2.827.. Test loss: 1.199.. Test accuracy: 0.641\n",
      "Epoch 46.. Step 10.. Train loss: 2.718.. Test loss: 1.229.. Test accuracy: 0.641\n",
      "Epoch 46.. Step 20.. Train loss: 2.677.. Test loss: 1.176.. Test accuracy: 0.641\n",
      "Epoch : 47\n",
      "Epoch 47.. Step 0.. Train loss: 2.493.. Test loss: 1.180.. Test accuracy: 0.641\n",
      "Epoch 47.. Step 10.. Train loss: 2.703.. Test loss: 1.173.. Test accuracy: 0.641\n",
      "Epoch 47.. Step 20.. Train loss: 2.614.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch : 48\n",
      "Epoch 48.. Step 0.. Train loss: 2.457.. Test loss: 1.458.. Test accuracy: 0.406\n",
      "Epoch 48.. Step 10.. Train loss: 2.550.. Test loss: 1.147.. Test accuracy: 0.641\n",
      "Epoch 48.. Step 20.. Train loss: 2.634.. Test loss: 1.359.. Test accuracy: 0.406\n",
      "Epoch : 49\n",
      "Epoch 49.. Step 0.. Train loss: 2.531.. Test loss: 1.162.. Test accuracy: 0.641\n",
      "Epoch 49.. Step 10.. Train loss: 2.702.. Test loss: 1.372.. Test accuracy: 0.406\n",
      "Epoch 49.. Step 20.. Train loss: 2.654.. Test loss: 1.151.. Test accuracy: 0.641\n",
      "Epoch : 50\n",
      "Epoch 50.. Step 0.. Train loss: 2.267.. Test loss: 1.446.. Test accuracy: 0.406\n",
      "Epoch 50.. Step 10.. Train loss: 2.578.. Test loss: 1.146.. Test accuracy: 0.641\n",
      "Epoch 50.. Step 20.. Train loss: 2.528.. Test loss: 1.119.. Test accuracy: 0.641\n",
      "Epoch : 51\n",
      "Epoch 51.. Step 0.. Train loss: 2.385.. Test loss: 1.160.. Test accuracy: 0.641\n",
      "Epoch 51.. Step 10.. Train loss: 2.650.. Test loss: 1.354.. Test accuracy: 0.406\n",
      "Epoch 51.. Step 20.. Train loss: 2.786.. Test loss: 1.141.. Test accuracy: 0.641\n",
      "Epoch : 52\n",
      "Epoch 52.. Step 0.. Train loss: 2.379.. Test loss: 1.338.. Test accuracy: 0.406\n",
      "Epoch 52.. Step 10.. Train loss: 2.747.. Test loss: 1.172.. Test accuracy: 0.641\n",
      "Epoch 52.. Step 20.. Train loss: 2.637.. Test loss: 1.397.. Test accuracy: 0.406\n",
      "Epoch : 53\n",
      "Epoch 53.. Step 0.. Train loss: 2.264.. Test loss: 1.174.. Test accuracy: 0.641\n",
      "Epoch 53.. Step 10.. Train loss: 2.720.. Test loss: 1.160.. Test accuracy: 0.641\n",
      "Epoch 53.. Step 20.. Train loss: 2.702.. Test loss: 1.390.. Test accuracy: 0.406\n",
      "Epoch : 54\n",
      "Epoch 54.. Step 0.. Train loss: 2.179.. Test loss: 1.374.. Test accuracy: 0.406\n",
      "Epoch 54.. Step 10.. Train loss: 2.589.. Test loss: 1.168.. Test accuracy: 0.641\n",
      "Epoch 54.. Step 20.. Train loss: 2.765.. Test loss: 1.391.. Test accuracy: 0.406\n",
      "Epoch : 55\n",
      "Epoch 55.. Step 0.. Train loss: 2.373.. Test loss: 1.342.. Test accuracy: 0.406\n",
      "Epoch 55.. Step 10.. Train loss: 2.675.. Test loss: 1.171.. Test accuracy: 0.641\n",
      "Epoch 55.. Step 20.. Train loss: 2.799.. Test loss: 1.329.. Test accuracy: 0.406\n",
      "Epoch : 56\n",
      "Epoch 56.. Step 0.. Train loss: 2.298.. Test loss: 1.179.. Test accuracy: 0.641\n",
      "Epoch 56.. Step 10.. Train loss: 2.675.. Test loss: 1.159.. Test accuracy: 0.641\n",
      "Epoch 56.. Step 20.. Train loss: 2.532.. Test loss: 1.364.. Test accuracy: 0.406\n",
      "Epoch : 57\n",
      "Epoch 57.. Step 0.. Train loss: 2.373.. Test loss: 1.142.. Test accuracy: 0.641\n",
      "Epoch 57.. Step 10.. Train loss: 2.581.. Test loss: 1.445.. Test accuracy: 0.406\n",
      "Epoch 57.. Step 20.. Train loss: 2.656.. Test loss: 1.139.. Test accuracy: 0.641\n",
      "Epoch : 58\n",
      "Epoch 58.. Step 0.. Train loss: 2.643.. Test loss: 1.162.. Test accuracy: 0.641\n",
      "Epoch 58.. Step 10.. Train loss: 2.621.. Test loss: 1.372.. Test accuracy: 0.406\n",
      "Epoch 58.. Step 20.. Train loss: 2.693.. Test loss: 1.181.. Test accuracy: 0.641\n",
      "Epoch : 59\n",
      "Epoch 59.. Step 0.. Train loss: 2.360.. Test loss: 1.164.. Test accuracy: 0.641\n",
      "Epoch 59.. Step 10.. Train loss: 2.680.. Test loss: 1.395.. Test accuracy: 0.406\n",
      "Epoch 59.. Step 20.. Train loss: 2.748.. Test loss: 1.350.. Test accuracy: 0.406\n",
      "Epoch : 60\n",
      "Epoch 60.. Step 0.. Train loss: 2.473.. Test loss: 1.430.. Test accuracy: 0.406\n",
      "Epoch 60.. Step 10.. Train loss: 2.749.. Test loss: 1.179.. Test accuracy: 0.641\n",
      "Epoch 60.. Step 20.. Train loss: 2.655.. Test loss: 1.196.. Test accuracy: 0.641\n",
      "Epoch : 61\n",
      "Epoch 61.. Step 0.. Train loss: 2.600.. Test loss: 1.188.. Test accuracy: 0.641\n",
      "Epoch 61.. Step 10.. Train loss: 2.506.. Test loss: 1.185.. Test accuracy: 0.641\n",
      "Epoch 61.. Step 20.. Train loss: 2.735.. Test loss: 1.181.. Test accuracy: 0.641\n",
      "Epoch : 62\n",
      "Epoch 62.. Step 0.. Train loss: 2.883.. Test loss: 1.173.. Test accuracy: 0.641\n",
      "Epoch 62.. Step 10.. Train loss: 2.639.. Test loss: 1.390.. Test accuracy: 0.406\n",
      "Epoch 62.. Step 20.. Train loss: 2.760.. Test loss: 1.200.. Test accuracy: 0.641\n",
      "Epoch : 63\n",
      "Epoch 63.. Step 0.. Train loss: 2.572.. Test loss: 1.184.. Test accuracy: 0.641\n",
      "Epoch 63.. Step 10.. Train loss: 2.694.. Test loss: 1.366.. Test accuracy: 0.406\n",
      "Epoch 63.. Step 20.. Train loss: 2.644.. Test loss: 1.179.. Test accuracy: 0.641\n",
      "Epoch : 64\n",
      "Epoch 64.. Step 0.. Train loss: 2.166.. Test loss: 1.366.. Test accuracy: 0.406\n",
      "Epoch 64.. Step 10.. Train loss: 2.726.. Test loss: 1.144.. Test accuracy: 0.641\n",
      "Epoch 64.. Step 20.. Train loss: 2.679.. Test loss: 1.434.. Test accuracy: 0.406\n",
      "Epoch : 65\n",
      "Epoch 65.. Step 0.. Train loss: 2.358.. Test loss: 1.147.. Test accuracy: 0.641\n",
      "Epoch 65.. Step 10.. Train loss: 2.567.. Test loss: 1.387.. Test accuracy: 0.406\n",
      "Epoch 65.. Step 20.. Train loss: 2.775.. Test loss: 1.372.. Test accuracy: 0.406\n",
      "Epoch : 66\n",
      "Epoch 66.. Step 0.. Train loss: 2.336.. Test loss: 1.372.. Test accuracy: 0.406\n",
      "Epoch 66.. Step 10.. Train loss: 2.570.. Test loss: 1.370.. Test accuracy: 0.406\n",
      "Epoch 66.. Step 20.. Train loss: 2.628.. Test loss: 1.124.. Test accuracy: 0.641\n",
      "Epoch : 67\n",
      "Epoch 67.. Step 0.. Train loss: 2.203.. Test loss: 1.115.. Test accuracy: 0.641\n",
      "Epoch 67.. Step 10.. Train loss: 2.556.. Test loss: 1.401.. Test accuracy: 0.406\n",
      "Epoch 67.. Step 20.. Train loss: 2.750.. Test loss: 1.118.. Test accuracy: 0.641\n",
      "Epoch : 68\n",
      "Epoch 68.. Step 0.. Train loss: 2.376.. Test loss: 1.141.. Test accuracy: 0.641\n",
      "Epoch 68.. Step 10.. Train loss: 2.779.. Test loss: 1.152.. Test accuracy: 0.641\n",
      "Epoch 68.. Step 20.. Train loss: 2.443.. Test loss: 1.407.. Test accuracy: 0.406\n",
      "Epoch : 69\n",
      "Epoch 69.. Step 0.. Train loss: 2.282.. Test loss: 1.387.. Test accuracy: 0.406\n",
      "Epoch 69.. Step 10.. Train loss: 2.603.. Test loss: 1.138.. Test accuracy: 0.641\n",
      "Epoch 69.. Step 20.. Train loss: 2.628.. Test loss: 1.462.. Test accuracy: 0.406\n",
      "Epoch : 70\n",
      "Epoch 70.. Step 0.. Train loss: 2.258.. Test loss: 1.413.. Test accuracy: 0.406\n",
      "Epoch 70.. Step 10.. Train loss: 2.774.. Test loss: 1.133.. Test accuracy: 0.641\n",
      "Epoch 70.. Step 20.. Train loss: 2.622.. Test loss: 1.402.. Test accuracy: 0.406\n",
      "Epoch : 71\n",
      "Epoch 71.. Step 0.. Train loss: 2.457.. Test loss: 1.354.. Test accuracy: 0.406\n",
      "Epoch 71.. Step 10.. Train loss: 2.675.. Test loss: 1.154.. Test accuracy: 0.641\n",
      "Epoch 71.. Step 20.. Train loss: 2.610.. Test loss: 1.148.. Test accuracy: 0.641\n",
      "Epoch : 72\n",
      "Epoch 72.. Step 0.. Train loss: 2.252.. Test loss: 1.171.. Test accuracy: 0.641\n",
      "Epoch 72.. Step 10.. Train loss: 2.462.. Test loss: 1.133.. Test accuracy: 0.641\n",
      "Epoch 72.. Step 20.. Train loss: 2.770.. Test loss: 1.501.. Test accuracy: 0.406\n",
      "Epoch : 73\n",
      "Epoch 73.. Step 0.. Train loss: 2.229.. Test loss: 1.903.. Test accuracy: 0.406\n",
      "Epoch 73.. Step 10.. Train loss: 2.577.. Test loss: 1.166.. Test accuracy: 0.641\n",
      "Epoch 73.. Step 20.. Train loss: 2.724.. Test loss: 1.162.. Test accuracy: 0.641\n",
      "Epoch : 74\n",
      "Epoch 74.. Step 0.. Train loss: 2.013.. Test loss: 1.393.. Test accuracy: 0.406\n",
      "Epoch 74.. Step 10.. Train loss: 2.640.. Test loss: 1.123.. Test accuracy: 0.641\n",
      "Epoch 74.. Step 20.. Train loss: 2.657.. Test loss: 1.436.. Test accuracy: 0.406\n",
      "Epoch : 75\n",
      "Epoch 75.. Step 0.. Train loss: 2.257.. Test loss: 1.156.. Test accuracy: 0.641\n",
      "Epoch 75.. Step 10.. Train loss: 2.578.. Test loss: 1.143.. Test accuracy: 0.641\n",
      "Epoch 75.. Step 20.. Train loss: 2.702.. Test loss: 1.403.. Test accuracy: 0.406\n",
      "Epoch : 76\n",
      "Epoch 76.. Step 0.. Train loss: 2.224.. Test loss: 1.405.. Test accuracy: 0.406\n",
      "Epoch 76.. Step 10.. Train loss: 2.501.. Test loss: 1.460.. Test accuracy: 0.406\n",
      "Epoch 76.. Step 20.. Train loss: 2.788.. Test loss: 1.136.. Test accuracy: 0.641\n",
      "Epoch : 77\n",
      "Epoch 77.. Step 0.. Train loss: 2.571.. Test loss: 1.357.. Test accuracy: 0.406\n",
      "Epoch 77.. Step 10.. Train loss: 2.610.. Test loss: 1.398.. Test accuracy: 0.406\n",
      "Epoch 77.. Step 20.. Train loss: 2.619.. Test loss: 1.349.. Test accuracy: 0.406\n",
      "Epoch : 78\n",
      "Epoch 78.. Step 0.. Train loss: 2.406.. Test loss: 1.169.. Test accuracy: 0.641\n",
      "Epoch 78.. Step 10.. Train loss: 2.639.. Test loss: 1.395.. Test accuracy: 0.406\n",
      "Epoch 78.. Step 20.. Train loss: 2.775.. Test loss: 1.179.. Test accuracy: 0.641\n",
      "Epoch : 79\n",
      "Epoch 79.. Step 0.. Train loss: 2.346.. Test loss: 1.362.. Test accuracy: 0.406\n",
      "Epoch 79.. Step 10.. Train loss: 2.699.. Test loss: 1.143.. Test accuracy: 0.641\n",
      "Epoch 79.. Step 20.. Train loss: 2.715.. Test loss: 1.171.. Test accuracy: 0.641\n",
      "Epoch : 80\n",
      "Epoch 80.. Step 0.. Train loss: 2.202.. Test loss: 1.188.. Test accuracy: 0.641\n",
      "Epoch 80.. Step 10.. Train loss: 2.743.. Test loss: 1.167.. Test accuracy: 0.641\n",
      "Epoch 80.. Step 20.. Train loss: 2.587.. Test loss: 1.160.. Test accuracy: 0.641\n",
      "Epoch : 81\n",
      "Epoch 81.. Step 0.. Train loss: 2.310.. Test loss: 1.122.. Test accuracy: 0.641\n",
      "Epoch 81.. Step 10.. Train loss: 2.595.. Test loss: 1.178.. Test accuracy: 0.641\n",
      "Epoch 81.. Step 20.. Train loss: 2.580.. Test loss: 1.384.. Test accuracy: 0.406\n",
      "Epoch : 82\n",
      "Epoch 82.. Step 0.. Train loss: 2.322.. Test loss: 1.373.. Test accuracy: 0.406\n",
      "Epoch 82.. Step 10.. Train loss: 2.550.. Test loss: 1.431.. Test accuracy: 0.406\n",
      "Epoch 82.. Step 20.. Train loss: 2.800.. Test loss: 1.160.. Test accuracy: 0.641\n",
      "Epoch : 83\n",
      "Epoch 83.. Step 0.. Train loss: 2.334.. Test loss: 1.346.. Test accuracy: 0.406\n",
      "Epoch 83.. Step 10.. Train loss: 2.552.. Test loss: 1.141.. Test accuracy: 0.641\n",
      "Epoch 83.. Step 20.. Train loss: 2.654.. Test loss: 1.400.. Test accuracy: 0.406\n",
      "Epoch : 84\n",
      "Epoch 84.. Step 0.. Train loss: 2.488.. Test loss: 1.164.. Test accuracy: 0.641\n",
      "Epoch 84.. Step 10.. Train loss: 2.581.. Test loss: 1.410.. Test accuracy: 0.406\n",
      "Epoch 84.. Step 20.. Train loss: 2.600.. Test loss: 1.135.. Test accuracy: 0.641\n",
      "Epoch : 85\n",
      "Epoch 85.. Step 0.. Train loss: 2.411.. Test loss: 1.368.. Test accuracy: 0.406\n",
      "Epoch 85.. Step 10.. Train loss: 2.810.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch 85.. Step 20.. Train loss: 2.519.. Test loss: 1.376.. Test accuracy: 0.406\n",
      "Epoch : 86\n",
      "Epoch 86.. Step 0.. Train loss: 2.339.. Test loss: 1.371.. Test accuracy: 0.406\n",
      "Epoch 86.. Step 10.. Train loss: 2.571.. Test loss: 1.125.. Test accuracy: 0.641\n",
      "Epoch 86.. Step 20.. Train loss: 2.790.. Test loss: 1.360.. Test accuracy: 0.406\n",
      "Epoch : 87\n",
      "Epoch 87.. Step 0.. Train loss: 2.332.. Test loss: 1.176.. Test accuracy: 0.641\n",
      "Epoch 87.. Step 10.. Train loss: 2.636.. Test loss: 1.187.. Test accuracy: 0.641\n",
      "Epoch 87.. Step 20.. Train loss: 2.803.. Test loss: 1.443.. Test accuracy: 0.406\n",
      "Epoch : 88\n",
      "Epoch 88.. Step 0.. Train loss: 2.485.. Test loss: 1.157.. Test accuracy: 0.641\n",
      "Epoch 88.. Step 10.. Train loss: 2.690.. Test loss: 1.341.. Test accuracy: 0.406\n",
      "Epoch 88.. Step 20.. Train loss: 2.514.. Test loss: 1.170.. Test accuracy: 0.641\n",
      "Epoch : 89\n",
      "Epoch 89.. Step 0.. Train loss: 2.529.. Test loss: 1.133.. Test accuracy: 0.641\n",
      "Epoch 89.. Step 10.. Train loss: 2.701.. Test loss: 1.396.. Test accuracy: 0.406\n",
      "Epoch 89.. Step 20.. Train loss: 2.510.. Test loss: 1.443.. Test accuracy: 0.406\n",
      "Epoch : 90\n",
      "Epoch 90.. Step 0.. Train loss: 2.304.. Test loss: 1.431.. Test accuracy: 0.406\n",
      "Epoch 90.. Step 10.. Train loss: 2.747.. Test loss: 1.149.. Test accuracy: 0.641\n",
      "Epoch 90.. Step 20.. Train loss: 2.718.. Test loss: 1.389.. Test accuracy: 0.406\n",
      "Epoch : 91\n",
      "Epoch 91.. Step 0.. Train loss: 2.446.. Test loss: 1.149.. Test accuracy: 0.641\n",
      "Epoch 91.. Step 10.. Train loss: 2.613.. Test loss: 1.343.. Test accuracy: 0.406\n",
      "Epoch 91.. Step 20.. Train loss: 2.512.. Test loss: 1.138.. Test accuracy: 0.641\n",
      "Epoch : 92\n",
      "Epoch 92.. Step 0.. Train loss: 2.313.. Test loss: 1.141.. Test accuracy: 0.641\n",
      "Epoch 92.. Step 10.. Train loss: 2.527.. Test loss: 1.384.. Test accuracy: 0.406\n",
      "Epoch 92.. Step 20.. Train loss: 2.577.. Test loss: 1.399.. Test accuracy: 0.406\n",
      "Epoch : 93\n",
      "Epoch 93.. Step 0.. Train loss: 2.401.. Test loss: 1.450.. Test accuracy: 0.406\n",
      "Epoch 93.. Step 10.. Train loss: 2.647.. Test loss: 1.104.. Test accuracy: 0.641\n",
      "Epoch 93.. Step 20.. Train loss: 2.544.. Test loss: 1.146.. Test accuracy: 0.641\n",
      "Epoch : 94\n",
      "Epoch 94.. Step 0.. Train loss: 2.568.. Test loss: 1.144.. Test accuracy: 0.641\n",
      "Epoch 94.. Step 10.. Train loss: 2.626.. Test loss: 1.335.. Test accuracy: 0.406\n",
      "Epoch 94.. Step 20.. Train loss: 2.718.. Test loss: 1.458.. Test accuracy: 0.406\n",
      "Epoch : 95\n",
      "Epoch 95.. Step 0.. Train loss: 2.115.. Test loss: 1.343.. Test accuracy: 0.406\n",
      "Epoch 95.. Step 10.. Train loss: 2.646.. Test loss: 1.138.. Test accuracy: 0.641\n",
      "Epoch 95.. Step 20.. Train loss: 2.651.. Test loss: 1.401.. Test accuracy: 0.406\n",
      "Epoch : 96\n",
      "Epoch 96.. Step 0.. Train loss: 2.329.. Test loss: 1.438.. Test accuracy: 0.406\n",
      "Epoch 96.. Step 10.. Train loss: 2.580.. Test loss: 1.143.. Test accuracy: 0.641\n",
      "Epoch 96.. Step 20.. Train loss: 2.798.. Test loss: 1.144.. Test accuracy: 0.641\n",
      "Epoch : 97\n",
      "Epoch 97.. Step 0.. Train loss: 2.426.. Test loss: 1.140.. Test accuracy: 0.641\n",
      "Epoch 97.. Step 10.. Train loss: 2.629.. Test loss: 1.401.. Test accuracy: 0.406\n",
      "Epoch 97.. Step 20.. Train loss: 2.577.. Test loss: 1.121.. Test accuracy: 0.641\n",
      "Epoch : 98\n",
      "Epoch 98.. Step 0.. Train loss: 2.655.. Test loss: 1.330.. Test accuracy: 0.406\n",
      "Epoch 98.. Step 10.. Train loss: 2.599.. Test loss: 1.186.. Test accuracy: 0.641\n",
      "Epoch 98.. Step 20.. Train loss: 2.690.. Test loss: 1.412.. Test accuracy: 0.406\n",
      "Epoch : 99\n",
      "Epoch 99.. Step 0.. Train loss: 2.555.. Test loss: 1.428.. Test accuracy: 0.406\n",
      "Epoch 99.. Step 10.. Train loss: 2.675.. Test loss: 1.205.. Test accuracy: 0.641\n",
      "Epoch 99.. Step 20.. Train loss: 2.636.. Test loss: 1.202.. Test accuracy: 0.641\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gc\n",
    "#del variables\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.NLLLoss()  \n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "# Training and Testing\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch : \"+str(epoch))\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        \n",
    "        b_x = Variable(x).to(device)   # batch x (image)\n",
    "        b_y = Variable(y).to(device)   # batch y (target)\n",
    "        \n",
    "        output = net(b_x)#.argmax(dim=1)\n",
    "        \"\"\"\n",
    "        print(\"b_y : \"+str(b_y))\n",
    "        print(\"shape b_y : \"+str(b_y.shape))    \n",
    "        print(\"output : \"+str(output))\n",
    "        print(\"shape output : \"+str(output.shape))\n",
    "        \"\"\"\n",
    "        loss = loss_func(output, b_y)   \n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Test -> this is where I have no clue\n",
    "        if step % 10 == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_dataloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = net(inputs)\n",
    "                    batch_loss = loss_func(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    wandb.log({\n",
    "                        \"epoch\":epoch,\n",
    "                        \"train loss\":running_loss/print_every,\n",
    "                        \"test loss\":test_loss/len(test_dataloader),\n",
    "                        \"test accuracy\":accuracy/len(test_dataloader),\n",
    "                        })\n",
    "            print(f\"Epoch {epoch}.. \"\n",
    "                  f\"Step {step}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(test_dataloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(test_dataloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            net.train()\n",
    "            torch.save(net, \"zooniverse-all-image_net_model.checkpt\")\n",
    "            wandb.save(\"zooniverse-all-image_net_model.checkpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"zooniverse-all-image_state_dict\")\n",
    "torch.save(net, \"zooniverse-all-image_net_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}